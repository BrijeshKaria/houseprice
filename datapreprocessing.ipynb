{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '{:.3f}'.format(x)) #Limiting floats output to 3 decimal points\n",
    "REMOVE_ONLY_2_Outliers = True\n",
    "USE_DUMMY_CAT_FEATURES = True\n",
    "STACK_MODELLING = True\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./data/train.csv')\n",
    "df_test =  pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 80)\n",
      "(1459, 79)\n"
     ]
    }
   ],
   "source": [
    "#Remove Id field as it is not useful in regression \n",
    "df_test_id = df_test['Id']\n",
    "#print(df_test_id)\n",
    "\n",
    "df_train.drop(['Id'],axis=1,inplace=True)\n",
    "df_test.drop(['Id'],axis=1,inplace=True)\n",
    "\n",
    "#df_train.drop(['Id','PoolQC','MiscFeature','Alley'],axis=1,inplace=True)\n",
    "#df_test.drop(['Id','PoolQC','MiscFeature','Alley'],axis=1,inplace=True)\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 80)\n"
     ]
    }
   ],
   "source": [
    "# Remove outliers  Reference - https://www.kaggle.com/zoupet/neural-network-model-for-house-prices-tensorflow\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "def RemoveOutliers(df_train):\n",
    "    if(REMOVE_ONLY_2_Outliers):\n",
    "        #Deleting outliers\n",
    "        df_train = df_train.drop(df_train[(df_train['GrLivArea']>4000) & (df_train['SalePrice']<300000)].index)\n",
    "    else:\n",
    "        clf = IsolationForest(max_samples = 100, random_state = 42)\n",
    "        clf.fit(df_train)\n",
    "        y_noano = clf.predict(df_train)\n",
    "        y_noano = pd.DataFrame(y_noano, columns = ['Top'])\n",
    "        y_noano[y_noano['Top'] == 1].index.values\n",
    "\n",
    "        df_train = df_train.iloc[y_noano[y_noano['Top'] == 1].index.values]\n",
    "        df_train.reset_index(drop = True, inplace = True)\n",
    "        print(\"Number of Outliers:\", y_noano[y_noano['Top'] == -1].shape[0])\n",
    "        print(\"Number of rows without outliers:\", df_train.shape[0])\n",
    "        \n",
    "RemoveOutliers(df_train)\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   12.248\n",
       "1   12.109\n",
       "2   12.317\n",
       "3   11.849\n",
       "4   12.429\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Log-transformation of the target variable\n",
    "#Handle skewness(Reference - https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard)\n",
    "#We use the numpy fuction log1p which  applies log(1+x) to all elements of the column\n",
    "df_train[\"SalePrice\"] = np.log1p(df_train[\"SalePrice\"])\n",
    "df_train[\"SalePrice\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_data size is : (2919, 79)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "ntrain = df_train.shape[0]\n",
    "ntest = df_test.shape[0]\n",
    "y_train_all = df_train.SalePrice.values\n",
    "all_data = pd.concat((df_train, df_test)).reset_index(drop=True)\n",
    "all_data.drop(['SalePrice'], axis=1, inplace=True)\n",
    "print(\"all_data size is : {}\".format(all_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datapreprocessing(all_data):\n",
    "    all_data[\"PoolQC\"] = all_data[\"PoolQC\"].fillna(\"None\")\n",
    "    all_data[\"MiscFeature\"] = all_data[\"MiscFeature\"].fillna(\"None\")\n",
    "    all_data[\"Alley\"] = all_data[\"Alley\"].fillna(\"None\")\n",
    "    all_data[\"Fence\"] = all_data[\"Fence\"].fillna(\"None\")\n",
    "    all_data[\"FireplaceQu\"] = all_data[\"FireplaceQu\"].fillna(\"None\")\n",
    "    \n",
    "    #Group by neighborhood and fill in missing value by the median LotFrontage of all the neighborhood\n",
    "    all_data[\"LotFrontage\"] = all_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))\n",
    "    for col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'):\n",
    "        all_data[col] = all_data[col].fillna('None')\n",
    "        \n",
    "    #Replacing missing data with 0 (Since No garage = no cars in such garage.)\n",
    "    for col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n",
    "        all_data[col] = all_data[col].fillna(0)\n",
    "        \n",
    "    # missing values are likely zero for having no basement\n",
    "    for col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n",
    "        all_data[col] = all_data[col].fillna(0)\n",
    "        \n",
    "    # For all these categorical basement-related features, NaN means that there is no basement.\n",
    "    for col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n",
    "        all_data[col] = all_data[col].fillna('None')\n",
    "        \n",
    "    #NA most likely means no masonry veneer for these houses. We can fill 0 for the area and None for the type.\n",
    "    all_data[\"MasVnrType\"] = all_data[\"MasVnrType\"].fillna(\"None\")\n",
    "    all_data[\"MasVnrArea\"] = all_data[\"MasVnrArea\"].fillna(0)\n",
    "    \n",
    "    # 'RL' is by far the most common value. So we can fill in missing values with 'RL'\n",
    "    all_data['MSZoning'] = all_data['MSZoning'].fillna(all_data['MSZoning'].mode()[0])\n",
    "    \n",
    "    #For this categorical feature all records are \"AllPub\", except for one \"NoSeWa\" and 2 NA . \n",
    "    #Since the house with 'NoSewa' is in the training set, this feature won't help in predictive modelling. \n",
    "    #We can then safely remove it.\n",
    "    all_data = all_data.drop(['Utilities'], axis=1)\n",
    "    \n",
    "    #data description says NA means typical\n",
    "    all_data[\"Functional\"] = all_data[\"Functional\"].fillna(\"Typ\")\n",
    "    \n",
    "    #It has one NA value. Since this feature has mostly 'SBrkr', we can set that for the missing value.\n",
    "    all_data['Electrical'] = all_data['Electrical'].fillna(all_data['Electrical'].mode()[0])\n",
    "    \n",
    "    #Only one NA value, and same as Electrical, we set 'TA' (which is the most frequent) for the missing value in KitchenQual.\n",
    "    all_data['KitchenQual'] = all_data['KitchenQual'].fillna(all_data['KitchenQual'].mode()[0])\n",
    "    \n",
    "    #Exterior 1 & 2 have only one missing value. We will just substitute in the most common string\n",
    "    all_data['Exterior1st'] = all_data['Exterior1st'].fillna(all_data['Exterior1st'].mode()[0])\n",
    "    all_data['Exterior2nd'] = all_data['Exterior2nd'].fillna(all_data['Exterior2nd'].mode()[0])\n",
    "    \n",
    "    all_data['SaleType'] = all_data['SaleType'].fillna(all_data['SaleType'].mode()[0])\n",
    "    all_data['MSSubClass'] = all_data['MSSubClass'].fillna(\"None\")\n",
    "    \n",
    "    #Transforming some numerical variables that are really categorical\n",
    "\n",
    "    #MSSubClass=The building class\n",
    "    all_data['MSSubClass'] = all_data['MSSubClass'].apply(str)\n",
    "\n",
    "\n",
    "    #Changing OverallCond into a categorical variable\n",
    "    all_data['OverallCond'] = all_data['OverallCond'].astype(str)\n",
    "\n",
    "\n",
    "    #Year and month sold are transformed into categorical features.\n",
    "    all_data['YrSold'] = all_data['YrSold'].astype(str)\n",
    "    all_data['MoSold'] = all_data['MoSold'].astype(str)\n",
    "    \n",
    "    \n",
    "#datapreprocessing(df_train)\n",
    "#datapreprocessing(df_test)\n",
    "datapreprocessing(all_data)\n",
    "\n",
    "#all_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape all_data: (2919, 79)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "def encodeCategories(all_data):\n",
    "    cols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n",
    "            'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n",
    "            'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n",
    "            'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', 'YrSold', 'MoSold')\n",
    "    # process columns, apply LabelEncoder to categorical features\n",
    "    for c in cols:\n",
    "        lbl = LabelEncoder() \n",
    "        lbl.fit(list(all_data[c].values)) \n",
    "        all_data[c] = lbl.transform(list(all_data[c].values))\n",
    "\n",
    "    # shape        \n",
    "    print('Shape all_data: {}'.format(all_data.shape))\n",
    "    #return \n",
    "    \n",
    "#encodeCategories(df_train)\n",
    "#encodeCategories(df_test)\n",
    "encodeCategories(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding total sqfootage feature \n",
    "#df_train['TotalSF'] = df_train['TotalBsmtSF'] + df_train['1stFlrSF'] + df_train['2ndFlrSF']\n",
    "#df_test['TotalSF'] = df_test['TotalBsmtSF'] + df_test['1stFlrSF'] + df_test['2ndFlrSF']\n",
    "all_data['TotalSF'] = all_data['TotalBsmtSF'] + all_data['1stFlrSF'] + all_data['2ndFlrSF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skew in numerical features: \n",
      "\n",
      "                Skew\n",
      "MiscVal       21.947\n",
      "PoolArea      16.898\n",
      "LotArea       12.822\n",
      "LowQualFinSF  12.089\n",
      "3SsnPorch     11.376\n",
      "LandSlope      4.975\n",
      "KitchenAbvGr   4.302\n",
      "BsmtFinSF2     4.146\n",
      "EnclosedPorch  4.004\n",
      "ScreenPorch    3.947\n",
      "There are 59 skewed numerical features to Box Cox transform\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "from scipy.stats import norm, skew #for some statistics\n",
    "\n",
    "skewness_threshold = 0.75\n",
    "\n",
    "def skewnesshandling(all_data):\n",
    "    numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n",
    "\n",
    "    # Check the skew of all numerical features\n",
    "    skewed_feats = all_data[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "    print(\"\\nSkew in numerical features: \\n\")\n",
    "    skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "    print(skewness.head(10))\n",
    "\n",
    "    skewness = skewness[abs(skewness) > skewness_threshold]\n",
    "    print(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n",
    "    \n",
    "    from scipy.special import boxcox1p\n",
    "    skewed_features = skewness.index\n",
    "    lam = 0.15\n",
    "    for feat in skewed_features:\n",
    "        #all_data[feat] += 1\n",
    "        all_data[feat] = boxcox1p(all_data[feat], lam)\n",
    "    \n",
    "    #all_data[skewed_features] = np.log1p(all_data[skewed_features])\n",
    "#skewnesshandling(df_train)\n",
    "#skewnesshandling(df_test)\n",
    "skewnesshandling(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold']\n",
      "['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition']\n"
     ]
    }
   ],
   "source": [
    "# Separate numerical and categorical columns\n",
    "def getNumericaldata(df,excludefield):\n",
    "    quantitative = [f for f in df.columns if df.dtypes[f] != 'object']\n",
    "    quantitative.remove(excludefield)\n",
    "    return quantitative\n",
    "\n",
    "def getCategoricaldata(df):\n",
    "    qualitative = [f for f in df.columns if df.dtypes[f] == 'object']\n",
    "    return qualitative\n",
    "\n",
    "numcols = getNumericaldata(df_train,'SalePrice')\n",
    "catcols = getCategoricaldata(df_train)\n",
    "alldata_catcols = getCategoricaldata(all_data)\n",
    "\n",
    "print(numcols)\n",
    "print(catcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2919, 223)\n"
     ]
    }
   ],
   "source": [
    "def convertasCategory(df,cols):\n",
    "    for col in cols:\n",
    "        df[col] = df[col].astype('category')\n",
    "        df[col+'_code'] = df[col].cat.codes\n",
    "        df[col] = df[col +'_code']\n",
    "        df.drop(labels=col+'_code', axis=\"columns\", inplace=True)\n",
    "    #return df\n",
    "\n",
    "if(USE_DUMMY_CAT_FEATURES):\n",
    "    #df_train = pd.get_dummies(df_train)\n",
    "    #print(df_train.shape)\n",
    "    #df_test = pd.get_dummies(df_test)\n",
    "    #print(df_test.shape)\n",
    "    all_data = pd.get_dummies(all_data)\n",
    "    print(all_data.shape)\n",
    "else:\n",
    "    convertasCategory(all_data,catcols)\n",
    "    #convertasCategory(df_train,catcols)\n",
    "    #convertasCategory(df_test,ccatcolsatcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining NAs for numerical features in all_data : 0\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "\n",
    "#print(df_train.head())\n",
    "#print(df_train.dtypes)\n",
    "# Handle remaining missing values for numerical features by using median as replacement\n",
    "#print(\"NAs for numerical features in train : \" + str(df_train.isnull().values.sum()))\n",
    "######df_train = df_train.fillna(df_train.median())\n",
    "######df_test = df_test.fillna(df_train.median())\n",
    "#print(\"Remaining NAs for numerical features in train : \" + str(df_train.isnull().values.sum()))\n",
    "#print(\"Remaining NAs for numerical features in test : \" + str(df_test.isnull().values.sum()))\n",
    "print(\"Remaining NAs for numerical features in all_data : \" + str(all_data.isnull().values.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropcols=['BldgType_1Fam', 'Condition1_Artery', 'Condition2_Artery','Exterior1st_AsbShng','Exterior1st_CBlock',\n",
    "#          'Exterior2nd_AsbShng','Foundation_BrkTil','GarageType_2Types','Heating_Floor','HouseStyle_1.5Fin',\n",
    "#          'LandContour_Bnk','LotConfig_Corner','MSZoning_C (all)','MasVnrType_BrkCmn','MiscFeature_Gar2',\n",
    " #         'Neighborhood_Blmngtn','RoofMatl_ClyTile','RoofStyle_Flat','SaleCondition_Abnorml','SaleType_COD',\n",
    "  #        'Utilities_AllPub','YearBuilt','YearRemodAdd','GarageYrBlt','TotalSF','GrLivArea','MiscFeature_None',\n",
    "   #       'PoolQC','RoofMatl_CompShg','Heating_GasA','1stFlrSF','Electrical_SBrkr','Condition2_Norm','GarageArea',\n",
    "    #      'RoofStyle_Gable','LotArea','Street','TotRmsAbvGrd','OverallQual','LotFrontage','KitchenAbvGr','TotalBsmtSF',\n",
    "     #     'MSZoning_RL','Exterior1st_VinylSd','GarageType_Attchd','GarageCond']\n",
    "dropcols=['YearRemodAdd', 'GrLivArea', '1stFlrSF', 'GarageArea', 'YearBuilt', 'TotRmsAbvGrd', 'LotFrontage',\n",
    "          'OverallQual', 'LotArea', 'TotalBsmtSF', 'KitchenAbvGr', 'GarageYrBlt', 'BedroomAbvGr', 'OverallCond', \n",
    "          'FullBath', 'GarageCars', 'MoSold', 'BsmtUnfSF']\n",
    "dropcols=[]\n",
    "#all_data = all_data.drop(dropcols,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 223)\n",
      "(1459, 223)\n"
     ]
    }
   ],
   "source": [
    "df_train_clean = all_data[:ntrain]\n",
    "df_test_clean = all_data[ntrain:]\n",
    "print(df_train_clean.shape)\n",
    "print(df_test_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_clean.to_csv('./data/train_X_clean.csv',index=False)\n",
    "df_test_clean.to_csv('./data/test_X_clean.csv',index=False)\n",
    "\n",
    "dataset = pd.DataFrame({'SalePrice': y_train_all})\n",
    "dataset.to_csv('./data/train_y_clean.csv',index=False)\n",
    "#print(dataset)\n",
    "#np.savetxt(\"./data/train_y_clean.csv\", y_train_all, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.24769912 12.10901644 12.31717117 ... 12.49313327 11.86446927\n",
      " 11.90159023]\n"
     ]
    }
   ],
   "source": [
    "print(y_train_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
